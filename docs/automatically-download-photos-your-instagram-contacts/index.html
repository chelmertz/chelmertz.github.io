<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Automatically download new photos from your Instagram contacts</title>

  <link rel="canonical" href="https://iamnearlythere.com/automatically-download-photos-your-instagram-contacts/">
  <link rel="alternate" type="application/rss+xml" title="iamnearlythere.com" href="/atom.xml">

  <link rel="stylesheet" href="/assets/tufte.css" />
  <link rel="stylesheet" href="/assets/chelmertz.css" />

</head>
<body>
  <script data-goatcounter="https://quepasa.goatcounter.com/count" async src="//gc.zgo.at/count.js"></script>
  <header role="banner"><h2><a href="/">iamnearlythere.com</a></h2></header>
    <main aria-label="Content">
      <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
        <header class="post-header">
          <h1 class="post-title" itemprop="name headline">Automatically download new photos from your Instagram contacts</h1>
          <p class="post-meta"><time datetime="2018-01-20T21:24:00Z" itemprop="datePublished">Jan 20, 2018</time></p>
        </header>
        <div class="post-content" itemprop="articleBody">
          <p>Let's say you want to downloaded the images uploaded to Instagram by you and your contacts, for backup reasons.</p>
<p>You can login at the regular web application at <a href="https://instagram.com">https://instagram.com</a> and <a href="https://honeypotmarketing.com/save-a-photo-from-instagram/">right-click/inspect your way to the actual URI of the image file</a>. Manually downloading one photo at a time soon becomes boring though, let's look for other alternatives.</p>
<p>There are a couple of sites that promote applications that does the job for you. The ones I saw wanted my username and password, which is out of the question.</p>
<p>Let's try to do download the images ourselves instead, from an environment we control, our desktop.</p>
<h2>Installing a scraper on your own computer to download photos</h2>
<p><em>The rest of this blog post assumes that you are using <strong>Linux or macOS</strong> (for <code>cron</code> and regular CLI tools), and have <strong>python</strong> installed (for the scraping program).</em></p>
<p>There's an easy to use <a href="https://en.wikipedia.org/wiki/Web_scraping">scraper</a> by Richard Arcega called <a href="https://github.com/rarcega/instagram-scraper/">Instagram Scraper</a> that we will use (version 1.5.18 at the time of writing). The scraper is available on <a href="https://pypi.python.org/pypi/instagram-scraper">pypi</a>, and you install it with:</p>
<pre><code>sudo pip install instagram-scraper
</code></pre>
<p>The next thing we are going to do is to configure who you are and which profiles you want to download. You do that by creating a text file:</p>
<pre><code>$ cat /home/ch/insta.txt
-u=username
-p=passwordinplaintext
--latest
--destination=/home/ch/Pictures/instagram
--retain_username
a_user_i_follow
another_user_i_follow
even_a_third_user_i_follow
</code></pre>
<p>Let's try it out:</p>
<pre><code>$ instagram-scraper @/home/ch/insta.txt
</code></pre>
<p>If you've got image files in the folder referred to by <code>--destination</code>, you are home free.</p>
<h2>Automating the scraping</h2>
<p>To avoid executing the above command manually, we use <a href="https://en.wikipedia.org/wiki/Cron">cron</a> to fetch new images for us.</p>
<p>This is what a my crontab looks like:</p>
<pre><code>$ crontab -l
1 * * * * /usr/bin/instagram-scraper -q @/home/ch/insta.txt
</code></pre>
<p>To edit your own crontab, use the command <code>crontab -e</code>.</p>
<p>If you need to learn the syntax of cron, there's a handy form at <a href="https://crontab.guru/">https://crontab.guru/</a> that could help you.</p>
<h2>Viewing newly downloaded images</h2>
<p>I use a minimal image viewer called <a href="https://github.com/muennich/sxiv">sxiv</a> which is available in the default repos of, at least, Fedora.</p>
<p>The following command let's you view all recently downloaded images:</p>
<pre><code>$ sxiv $(find /home/ch/Pictures/instagram -mtime -10 -type f -name &quot;*jpg&quot;)
</code></pre>
<p>where the first argument to <code>find</code> is the value of <code>--destination</code> in your configuration, and <code>-10</code> let's you view images from the last ten days.</p>
<h2>Caveats</h2>
<h3>Notes about availability of images</h3>
<p>All images uploaded to Instagram, even by those with their profiles set to private, are publicly accessible. Getting to know the URI is the only problem, that's why we use the scraping application, to find the correct URIs. Even though the URIs themselves do not require being authenticated to download, there may be rate limits or other counter measures against downloading images in bulk.</p>
<h3>Shortcuts in the code</h3>
<ul>
<li>Feel free to <code>pip install --user</code> instead.</li>
<li>Feel free to capture the stdout/stderr from the cronjob.</li>
</ul>
<p>*[URI]: Uniform Resource Identifier
*[CDN]: Content delivery network</p>

        </div>
      </article>
      <section class="related-posts">
        <h2>Possibly related posts</h2>
        <ul>
          <li><a href="/trying-out-closure">Trying out closure</a></li>
          <li><a href="/jenkins-python-virtualenv">Making Jenkins work with python&#39;s virtualenv</a></li>
          <li><a href="/search-ack-better-grep">search with ack - &#34;better than grep&#34;</a></li>
          <li><a href="/dark-mode-ubuntu-i3">Toggling light/dark color scheme for i3 on Ubuntu</a></li>
          <li><a href="/new-dev-area-with-gitweb">New dev area with gitweb</a></li>
        </ul>
      </section>
    </main>
    <footer>
      <p>by Carl Helmertz â€” <a href="mailto:helmertz@gmail.com">helmertz@gmail.com</a><br/><a href="https://helmertz.com">https://helmertz.com</a> <a href="https://github.com/chelmertz">github.com/chelmertz</a></p>
    </footer>
  </body>
</html>
